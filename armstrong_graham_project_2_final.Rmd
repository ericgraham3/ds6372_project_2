---
title: "DS 6372 Project 2"
author: "Blake Armstrong and Eric Graham"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
---

# 1: Setup

```{r setup, include=FALSE}
load_or_install = function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

packages = c(
  "tidyverse",
  "skimr",
  "naniar",
  "corrplot",
  "ggthemes",
  "caret",
  "knitr",
  "car",
  "lmboot",
  "glmnet",
  "randomForest",
  "pROC"
)
invisible(lapply(packages, load_or_install))
```

```{r}
df = read.csv2("bank-additional-full.csv", header = TRUE)
names(df)
str(df)
head(df)
```

# 2: Exploratory Data Analysis

As we see above the Bank Marketing dataset includes 41,188 rows and 21 columns. The dataset contains information about clients of a banking institution and whether they subscribed to a term deposit. To approach the question of "How can we predict whether a client will subscribe to a term deposit?" we will perform exploratory data analysis (EDA) to understand the data, identify patterns, and prepare for modeling.

## Variable Classification and Basic Cleaning

```{r}
df = df %>% mutate(
  emp.var.rate = as.numeric(emp.var.rate),
  cons.price.idx = as.numeric(cons.price.idx),
  cons.conf.idx = as.numeric(cons.conf.idx),
  euribor3m = as.numeric(euribor3m),
  nr.employed = as.numeric(nr.employed),
  poutcome = as.factor(poutcome),
  y = factor(y, levels = c("no", "yes")),
  pdays_missing = pdays == 999,
  poutcome_missing = poutcome == "nonexistent")
str(df)
```

Aside from some basic datatype conversions, the dataset glossary shows that the value "999" designates that the client was not previously contacted. Thus, we create a new boolean variable `pdays_missing` to indicate whether the `pdays` value is 999.

You would expect that this would match up with the number of "nonexistent" results on the poutcome variable, which indicates the outcome of prior marketing attempts. However, that is not the case:

```{r}
table(df$pdays_missing, df$poutcome_missing)
```

We see 4110 records for which the pdays value was 999, but the prior outcome is not flagged as "nonexistent." 

```{r}
df %>%
  filter(pdays_missing) %>%
  group_by(poutcome) %>%
  summarize(count = n())
```

This is contradictory: the poutcome values here imply that the client was previously contacted, and that the attempt failed, but the pdays value indicates that the client was never contacted. This is a data quality issue that we will need to address in our analysis.

```{r}
target_var = "y"

num_vars = df %>% dplyr::select(where(is.numeric)) %>% names()
num_vars = setdiff(num_vars, target_var)

cat_vars = setdiff(names(df), c(num_vars, target_var))
cat_vars
# num_vars
```

```{r}
# head(df)
# glimpse(df)
skim(df)
```

The skim() function provides a summary of the dataset, and we see no missing values. 

## Variable Glossary

```{r}
data.frame(
  Variable_Name = c(
    "Age", "Job", "Marital", "Education", "Default", "Housing", "Loan",
    "Contact", "Month", "Day_of_week", "Duration",
    "Campaign", "Pdays", "Previous", "Poutcome",
    "Emp.var.rate", "Cons.price.idx", "Cons.conf.idx",
    "Euribor3m", "Nr.employed", "y"
  ),
  Description = c(
    "Client age in years",
    "Type of job (e.g., admin., technician, retired, etc.)",
    "Marital status (married, single, divorced/widowed, unknown)",
    "Education level (e.g., basic.4y, high school, university, etc.)",
    "Has credit in default? (yes, no, unknown)",
    "Has housing loan? (yes, no, unknown)",
    "Has personal loan? (yes, no, unknown)",
    "Contact communication type (cellular or telephone)",
    "Last contact month of the year",
    "Last contact day of the week",
    "Last contact duration (in seconds)",
    "Number of contacts during this campaign (includes last contact)",
    "Days since client was last contacted (999 = not previously contacted)",
    "Number of contacts before this campaign",
    "Outcome of the previous marketing campaign",
    "Employment variation rate (quarterly)",
    "Consumer price index (monthly)",
    "Consumer confidence index (monthly)",
    "3-month Euribor rate (daily)",
    "Number of employees (quarterly)",
    "Client subscribed to a term deposit? (yes or no)"
  ),
  `Data Type` = c(
    "integer", "character", "character", "character", "character", "character", "character",
    "character", "character", "character", "integer",
    "integer", "integer", "integer", "factor",
    "numeric", "numeric", "numeric",
    "numeric", "numeric", "factor"
  ),
  Type = c(
    "continuous", "categorical", "categorical", "categorical", "categorical", "categorical", "categorical",
    "categorical", "categorical", "categorical", "continuous",
    "discrete", "discrete", "discrete", "categorical",
    "continuous", "continuous", "continuous",
    "continuous", "continuous", "binary"
  )
) |>
  kable()
```

## Univariate Analysis

```{r}
label_dict = c(
  "age" = "Age",
  "job" = "Job",
  "marital" = "Marital Status",
  "education" = "Education",
  "default" = "Default",
  "housing" = "Housing Loan",
  "loan" = "Personal Loan",
  "contact" = "Contact Type",
  "month" = "Month",
  "day_of_week" = "Day of Week",
  "duration" = "Duration",
  "campaign" = "Campaign Contacts",
  "pdays" = "Days Since Last Contact",
  "previous" = "Previous Contacts",
  "poutcome" = "Previous Outcome",
  "emp.var.rate" = "Employment Variation Rate",
  "cons.price.idx" = "Consumer Price Index",
  "cons.conf.idx" = "Consumer Confidence Index",
  "euribor3m" = "Euribor 3 Month Rate",
  "nr.employed" = "Number of Employees",
  "y" = "Subscribed"
)

pretty_var = function(x) {
  gsub("_", " ", tools::toTitleCase(x))
}

get_label = function(varname) {
  if (varname %in% names(label_dict)) {
    return(label_dict[[varname]])
  } else {
    return(pretty_var(varname))
  }
}
```

### Distribution of Response Variable

We see the overwhelming number of clients did not subscribe to a term deposit, with only about 11% of the clients subscribing. This will come as no surprise to those who have ever worked in an outbound call center.

```{r}
p = ggplot(df, aes(x = y)) +
  geom_bar(fill = "steelblue", color = "white") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
  labs(
    x = "Subscribed",
    y = "Count",
    title = "Subscription Outcome"
  ) +
  theme_minimal()
print(p)

p2 = ggplot(df, aes(x = y)) +
  geom_bar(aes(y = after_stat(prop), group = 1), fill = "steelblue", color = "white") +
  geom_text(
    aes(y = after_stat(prop), label = scales::percent(after_stat(prop)), group = 1),
    stat = "count",
    vjust = -0.5,
    color = "black",
    size = 4
  ) +
  labs(
    x = "Subscribed",
    y = "Proportion",
    title = "Subscription Outcome (Proportions)"
  ) +
  theme_minimal()
print(p2)

```

### Numeric Predictors

<details>
<summary>Click to expand: Numeric Variable Plots</summary>

```{r}
for (var in num_vars) {
  p = ggplot(df, aes(x = !!sym(var))) +
    geom_histogram(fill = "steelblue", color = "white") +
    labs(
      x = get_label(var),
      title = paste("Distribution of", get_label(var))
    ) +
    theme_minimal()
  print(p)
}
```

```{r}
for (var in num_vars) {
  p = ggplot(df, aes(y = !!sym(var))) +
    geom_boxplot(fill = "steelblue") +
    coord_flip() +
    labs(y = get_label(var), title = paste("Boxplot of", get_label(var))) +
    theme_minimal()
  print(p)
}
```

</details>

We note that age is fairly right-skewed. Duration and campaign contacts are highly right-skewed. However, duration is especially problematic in a predictive contect—the duration of the call can't be known at prediction time, so it will be excluded from Objective 2. Consumer confidence is left-skewed. 

Pdays, as noted above, has a high number of 999 values, so we will be analyzing it as a boolean categorical variable rather than a numeric one.

Likewise, "previous contacts" has a high number of zeroes, with few unique values; we may consider this as a factor as well.

Employment Variation Rate and the Euribor 3-Month Rate may also be best handled as a "stealth" categorical variable.

The number of employees has so little variance that it might not bring any explanatory or predictive power to the model.

#### Transformations

```{r}
df = df %>%
  mutate(
    duration_log = log(duration + 1),
    campaign_log = log(campaign + 1),
    
    prev_contacts_binned = case_when(
      previous == 0 ~ "0",
      previous == 1 ~ "1",
      previous >= 2 ~ "2+"
    ),
    
    euribor_binned = case_when(
      euribor3m < 1 ~ "<1",
      euribor3m >= 5 ~ "5+",
      TRUE ~ as.character(floor(euribor3m))
    )
  )

df = df %>%
  mutate(
    prev_contacts_binned = factor(prev_contacts_binned, levels = c("0", "1", "2+")),
    euribor_binned = factor(euribor_binned, levels = c("<1", "1", "2", "3", "4", "5", "5+"))
  )

num_vars = c(num_vars, "duration_log", "campaign_log")
cat_vars = c(cat_vars, "prev_contacts_binned", "euribor_binned")

# num_vars
# cat_vars

```

We binned the number of previous contacts and Euribor values, and include them with the other categorical variables.

The call duration and number of contacts in the campaign may be useful for EDA and interpretive modeling, so we log-transform them to see if it addresses the skewness. 

```{r}
log_vars = c("duration_log", "campaign_log")

for (var in log_vars) {
  p = ggplot(df, aes(x = !!sym(var))) +
    geom_histogram(fill = "steelblue", color = "white", bins = 30) +
    labs(
      x = get_label(var),
      title = paste("Distribution of", get_label(var))
    ) +
    theme_minimal()
  print(p)

  p = ggplot(df, aes(y = !!sym(var))) +
    geom_boxplot(fill = "steelblue") +
    coord_flip() +
    labs(
      y = get_label(var),
      title = paste("Boxplot of", get_label(var))
    ) +
    theme_minimal()
  print(p)
}
```

The log transformation appears to help a great deal with the skewness of duration, but has only a mild effect on the current campaign contacts. This may be another opportunity for binning, so we will look at a binned version of campaign contacts in the categorical analysis.

```{r}
df = df %>%
  mutate(campaign_bin = case_when(
    campaign == 1 ~ "1",
    campaign %in% 2:3 ~ "2–3",
    campaign >= 4 ~ "4+"
  )) %>%
  mutate(campaign_bin = factor(campaign_bin, levels = c("1", "2–3", "4+")))

cat_vars = c(cat_vars, "campaign_bin")
# cat_vars
```


### Categorical Variables

<details>
<summary>Click to expand: Categorical Variable Plots</summary>

```{r}
for (var in cat_vars) {
  p = ggplot(df, aes(x = !!sym(var))) +
    geom_bar(fill = "steelblue") +
    labs(
      x = get_label(var),
      y = "Count",
      title = paste("Frequency of", get_label(var))
    ) +
    theme_minimal()
  print(p)
}
```

</details>

We note that the job variable is imbalanced, with a large number of job titles but a handful of them having a large number of clients. 

The default variable includes many "no" values, a small number of "unknown" values, and only three "yes" values. This stands out as a variable with potentially little predictive power.


```{r}
df %>%
  count(default)
```

Likewise, the highly imbalanced results of "previous days missing" with "previous outcome missing" is concerning, given the data quality question mentioned above. This will be something to watch closely when examining the relationship with the response variable.

We note that the binning of previous campaign contacts, current campaign contacts, and Euribor 3-Month Rate has yielded a more interpretable set of categorical variables.

### Outlier Analysis

```{r}
outlier_summary = data.frame()

for (var in num_vars) {
  values = df[[var]]
  q1 = quantile(values, 0.25, na.rm = TRUE)
  q3 = quantile(values, 0.75, na.rm = TRUE)
  iqr = q3 - q1
  lower = q1 - 1.5 * iqr
  upper = q3 + 1.5 * iqr
  outliers = sum(values < lower | values > upper, na.rm = TRUE)
  pct = 100 * outliers / sum(!is.na(values))
  outlier_summary = rbind(
    outlier_summary,
    data.frame(variable = var, num_outliers = outliers, pct_outliers = round(pct, 1))
  )
}

outlier_summary
```

We conducted an outlier analysis across all numeric variables using IQR to identify extreme values. While some variables like duration, campaign, and previous showed moderate to high outlier proportions, we have already managed those via log transformation and binning. 

## Bivariate / Multivariate Analysis

### Subscriptions by Numeric Predictors

<details>
<summary>Click to expand: Numeric Bivariate Plots</summary>

```{r}
for (var in num_vars) {
  p = ggplot(df, aes(x = !!sym(var), y = y)) +
    geom_boxplot(aes(group = y), fill = "steelblue", alpha = 0.7) +
    labs(
      x = get_label(var),
      y = "Subscribed",
      title = paste("Subscription Outcome by", get_label(var))
    ) +
    theme_minimal()
  print(p)
}
```

```{r}
df$y_numeric = as.numeric(df$y == "yes")
for (var in num_vars) {
  p = ggplot(df, aes(x = !!sym(var), y = y_numeric)) +
    geom_point(alpha = 0.2, size = 0.8) +
    geom_smooth(method = "loess", se = FALSE, color = "steelblue", linewidth = 1) +
    labs(
      x = get_label(var),
      y = "Probability of Subscription",
      title = paste("Subscription Probability vs", get_label(var))
    ) +
    theme_minimal()
  print(p)
}

```


</details>

We note little difference between the median ages on the two subscription outcomes, leading us to think it might be a weak predictor. Likewise, number of employees (previously noted as having low variance) appears to be a weak predictor.

Subscribers skew towards lower employment variation rates, leading us to think that this may be a useful predictor. Subscribers also tend to have lower consumer confidence values than non-subscribers. Lower Euribor rates are also associated with subscription. This may capture the economic conditions at the time of the marketing campaign, which could be a useful predictor, but we will assess the binned version of this variable below.

We note that the log of duration is much higher among subscribers, which makes intuitive sense. As noted previously, this is not useful for predictive modeling, but it may be useful for interpretive modeling.

### Subscriptions by Categorical Predictors

<details>
<summary>Click to expand: Categorical Bivariate Plots</summary>

```{r}
for (var in cat_vars) {
  p = df %>%
    group_by(!!sym(var)) %>%
    summarise(prop_yes = mean(y == "yes")) %>%
    ggplot(aes(x = !!sym(var), y = prop_yes)) +
    geom_col(fill = "steelblue") +
    geom_text(aes(label = scales::percent(prop_yes)), vjust = -0.5) +
    labs(
      x = get_label(var),
      y = "Proportion Subscribed",
      title = paste("Subscription Rate by", get_label(var))
    ) +
    theme_minimal()
  print(p)
}
```

</details>

We note that job, marital status, education, contact type, month, day, and previous outcome all have significant differences in subscription rates, and may be useful predictors. 

Clients with prior campaign contact (pdays_missing = FALSE) and a recorded previous outcome (poutcome ≠ unknown) are substantially more likely to subscribe. Due to overlap in what they convey, we may choose to retain only one: poutcome captures both the presence and outcome of prior engagement.

Binning the number of previous and current campaign contacts revealed clearer patterns. Subscription rates were much lower among clients with no prior contacts, and current campaign contact counts show a declining trend, hinting at diminishing returns from repeated contact.

We also see that the Euribor 3-Month Rate binned variable has a strong relationship with the response variable, with rates at either extreme having a high subscription rate. This suggests that the economic conditions at the time of the marketing campaign may be a useful predictor.

As noted previously, the default variable has very few "yes" values, and the housing and loan variables also show very similar rates for all levels. These seem to have little explanatory power, and we may consider dropping them from the model. 

### Multicollinearity Check

```{r}
cor_data = df %>% dplyr::select(all_of(num_vars))

cor_matrix = cor(cor_data, use = "complete.obs")

corrplot(cor_matrix,
         method = "color",       
         type = "upper",         
         order = "hclust",       
         addCoef.col = "black",  
         tl.cex = 0.8,           
         number.cex = 0.7,       
         diag = FALSE)
```

The correlation matrix shows that there is high collinearlity among our macroeconomic predictors: Euribor is highly collinear with employment, and  consumer price index is moderately correlated with both of those predictors.

```{r}
eda_vif_model = glm(
  y ~ age + emp.var.rate + cons.price.idx + cons.conf.idx +
      euribor3m + nr.employed + duration_log + campaign_log,
  data = df,
  family = binomial
)
vif(eda_vif_model)

```

A VIF analysis confirms that the employment variation rate, consumer price index, and Euribor 3-Month Rate have high VIF values, indicating multicollinearity. 



# 3: Interpretive Model

## Data Preparation

```{r}
set.seed(1234)
train_proportion = 0.7
train_indices = sample(1:nrow(df), size = floor(train_proportion * nrow(df)))
train_df = df[train_indices, ]
test_df = df[-train_indices, ]
```

## Feature Selection Considerations

Based on exploratory data analysis, we find that duration_log, campaign_log, cons.conf.idx, euribor3m, contact, month, poutcome, job, and education are potentially useful predictors in fitting an interpretive model.

The campaign_bin transformation may be more useful than the log-transformed version, as it captures the diminishing returns of repeated contacts. This is an open question, and we will test both versions in the model.

Euribor 3-Month Rate is highly collinear with employment variation rate and consumer price index, so we will need to choose one of these macroeconomic predictors to include in the model. Euribor has a more direct relationship with the response in our EDA, so we will include it in the model. 

There is a decision to make as to whether we prefer the binned or continuous version of euribor3m. The relationship between the binned version and the response variable is clearer in the EDA, and more interpetable, so we will use it in the interpretive model, but the numeric version may be more appropriate for the predictive model.

Given the data quality issues surrounding the original pdays variable, and its redundancy with poutcome, we will not include it in the model. Instead, we will use poutcome, which offers more detailed information about prior marketing attempts without the data quality issues. We will not include the raw or binned version of previous contacts to avoid overlap, since poutcome is more informative and interpretable.

## Baseline Model (All Predictors, No Transformations)

To provide a baseline for comparison, we will fit a model using all numeric and categorical predictors, excluding the problematic pdays variable. This model includes no transformations.

```{r}
baseline_model_raw = glm(
  y ~ age + duration + campaign + pdays + previous +
      emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed +
      job + marital + education + default + housing + loan +
      contact + month + day_of_week + poutcome,
  data = train_df,
  family = binomial
)

summary(baseline_model_raw)
```

## Baseline Model (All Predictors, With Transformations)

```{r}
baseline_model = glm(
  y ~ duration_log + campaign_log + cons.conf.idx + euribor_binned +
      job + marital + education + default + housing + loan +
      contact + month + day_of_week + poutcome +
      pdays_missing + poutcome_missing + prev_contacts_binned + campaign_bin,
  data = train_df,
  family = binomial
)
summary(baseline_model)
```

## Feature-Selection Models

### Log Transformation for Campaign

```{r}
model_campaign_log = glm(
  y ~ duration_log + campaign_log + cons.conf.idx + euribor_binned +
      contact + month + poutcome + job + education,
  data = train_df,
  family = binomial
)
summary(model_campaign_log)
```

### Binned Transformation for Campaign

```{r}
model_campaign_bin = glm(
  y ~ duration_log + campaign_bin + cons.conf.idx + euribor_binned +
      contact + month + poutcome + job + education,
  data = train_df,
  family = binomial
)
summary(model_campaign_bin)

ctrl = caret::trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = caret::twoClassSummary, savePredictions = "final", allowParallel = FALSE, verboseIter = TRUE)
slr_cv = caret::train(
  y ~ duration_log + campaign_bin + cons.conf.idx + euribor_binned +
      contact + month + poutcome + job + education,
  data = train_df,
  method = "glm",
  family = binomial,
  metric = "ROC",
  trControl = ctrl
)

probs = predict(model_campaign_bin, newdata = test_df, type = "response")
threshold = 0.5
preds = ifelse(probs >= threshold, "yes", "no")
preds = factor(preds, levels = levels(test_df$y))
conf = caret::confusionMatrix(preds, test_df$y, positive = "yes")

sensitivity = conf$byClass["Sensitivity"]
specificity = conf$byClass["Specificity"]
ppv = conf$byClass["Pos Pred Value"]
npv = conf$byClass["Neg Pred Value"]
prevalence = mean(test_df$y == "yes")

clr_roc_obj = pROC::roc(response = test_df$y, predictor = as.numeric(probs), levels = c("no", "yes"))
auroc = pROC::auc(clr_roc_obj)

slr_results = list(
  Sensitivity = sensitivity,
  Specificity = specificity,
  PPV = ppv,
  NPV = npv,
  Prevalence = prevalence,
  AUROC = auroc
)
print(slr_results)

```


### Comparison

| Model                    | Description                       | AIC    |
|--------------------------|-----------------------------------|--------|
| `baseline_model_raw`     | All raw variables, no EDA         | 11903  |
| `baseline_model`         | All transformations, no feature selection   | 11405  |
| `model_campaign_log`     | Selected vars + campaign_log      | 11413  |
| `model_campaign_bin`     | Selected vars + campaign_bin      | 11409  |

We began with a baseline logistic regression model that included all available raw predictors with no transformations or feature selection. This “kitchen sink” model achieved an AIC of 11,903. We will call this the "raw baseline model."

We then fit a model with all transformed variables, which achieved an AIC of 11405. We will call this the "baseline model."

Lastly, we fit a model with selected features and tranformations based on EDA and interpretability. Our trimmed, transformed model using selected predictors produced an AIC of 11,409. We will call this the "feature-selected model."

While the baseline model slightly outperformed the feature-selected model in terms of AIC, the feature-selected model is more interpretable and avoids variables with data quality issues, high collinearity, or unclear relationships to the response. These variables may prove valuable in our predictive model, but for interpretive purposes, we will use the feature-selected model as our final model.

### Assumptions Check

We assessed the key assumptions of logistic regression and found no meaningful violations. 

To address nonlinearity in the numeric predictors, we applied a log transformation to both duration and campaign, and binned euribor3m into discrete categories, all of which showed skewed or nonlinear relationships in EDA. 

Multicollinearity was addressed by excluding highly correlated economic variables such as emp.var.rate, cons.price.idx, and nr.employed, based on a correlation matrix check and VIF analysis. 

We assume independence of observations based on the dataset's structure, where each row represents a unique client interaction, and outliers were managed through transformation rather than deletion. 

## Interpretation

### Call Duration (duration_log)

As expected, call duration is a very strong predictor, but it is not useful for predictive modeling, as it cannot be known at prediction time. Intuitively, one would expect that a longer call would be associated with a higher likelihood of subscription, and this is confirmed by the model. 

The odds ratio of 1.23 indicates that for a one-unit increase in log(duration + 1), which is approximately a 2.72-fold increase in the original call duration, the odds of subscribing increase by 23%. This relationship is highly significant (p < 0.001), indicating a strong positive relationship between call length and subscription likelihood.

### Campaign Contact Frequency (campaign_bin)

Compared to clients contacted once, those contacted 2–3 times have lower odds of subscribing (-0.16), and the effect for 4+ contacts is similar (-0.14) but statistically not significant (p-value 0.06).  This supports the idea that repeated contact may not improve — and may hurt — effectiveness.

### Euribor 3-Month Rate (euribor_binned)

Lower Euribor rates are associated with higher subscription rates. Using <1 as the reference category, customers with an Euribor 3-month rate in bin 1 have odds of subscribing that are about 42% lower (OR ≈ 0.58) than those in the <1 bin, a difference that is statistically significant (p < 0.001).

### Consumer Confidence Index (cons.conf.idx)

Similar to Euribor, consumer confidence also shows a small positive relationship: the coefficient for consumer confidence index is 0.031 (OR ≈ 1.03), meaning that for each one-point increase in the index, the odds of a customer subscribing to a term deposit increase by about 3%. This effect is statistically significant (p < 0.001).

### Contact Type (contact)

Using cellular as the reference category, customers contacted by telephone have odds of subscribing that are about 16% lower (OR ≈ 0.84). This difference is statistically significant (p ≈ 0.042). This data was from a paper published in 2014, so one could reasonably expect even less effectiveness of telephone contact today.

### Month of Contact (month)

Compared to April, the odds of a customer subscribing are significantly higher in most months, with the largest effect in March—odds are over six times greater (OR ≈ 6.51, p < 0.001). June (OR ≈ 2.15), October (OR ≈ 1.95), November (OR ≈ 1.85), July (OR ≈ 1.76), September (OR ≈ 1.45), and August (OR ≈ 1.42) also show significantly higher odds.

In contrast, May shows significantly lower odds of subscription (OR ≈ 0.54, p < 0.001).

December shows higher odds (OR ≈ 1.58), but the effect is not statistically significant at the 0.05 level (p ≈ 0.078).

### Outcome of Previous Campaign Efforts (poutcome)

Clients with a successful outcome in a previous campaign have significantly higher odds of subscribing again (2.02), while even those with no previous campaign (nonexistent) show a positive effect compared to the baseline (failure). The p-values for these predictors are less than 0.001, indicating a strong relationship. This suggests that prior successful engagement is a strong predictor of future subscription, and that clients who were not previously contacted are more likely to subscribe than those who had previously declined.

### Job Type (job)

As we expected from EDA, the job category has mixed effects. Students and retirees show higher odds of subscribing, while blue-collar workers show significantly lower odds.

### Education Level (education)

Education level also shows mixed effects. Only the university degree category shows a significant positive effect (0.28, p-value0.00866), suggesting limited differentiation among education levels.

# 4: Predictive Model 1 (Complex Logistic Regression)

## Data Preparation

### Important Note re: duration and pdays 

As noted previously, we don't consider call duration to be a valid predictor of subscription, since it's a variable that wouldn't be known at the time of contact. 

We are also proceeding with caution in our use of the pdays variable, given the previously-noted data quality issues. We will not include it in the predictive model, but we will include a boolean variable indicating whether the pdays value was missing (999). This will allow us to capture the effect of not having a previous contact without relying on the potentially problematic pdays variable itself.

```{r}
set.seed(1234)

selected_features <- c(
  "age",
  "job",
  "marital",
  "education",
  "default",
  "housing",
  "loan",
  "contact",
  "month",
  "day_of_week",
  # "pdays",
  "poutcome",
  "emp.var.rate",
  "cons.price.idx",
  "cons.conf.idx",
  "nr.employed",
  "pdays_missing",
  # "poutcome_missing",
  "campaign_bin",
  "prev_contacts_binned",
  "euribor_binned",
  "y_numeric"
)

df_clr_filtered <- df[, selected_features]

train_proportion <- 0.7
train_indices <- sample(seq_len(nrow(df_clr_filtered)), size = floor(train_proportion * nrow(df_clr_filtered)))

train_df <- df_clr_filtered[train_indices, ]
test_df  <- df_clr_filtered[-train_indices, ]

names(train_df)
```

## Feature Selection with LASSO

As we look to extend our model for predictive puroses, we will begin with LASSO regression to select features. LASSO is particularly useful for high-dimensional datasets, as it performs both variable selection and regularization to enhance prediction accuracy and interpretability.

```{r}
X = model.matrix(y_numeric ~ . - 1, data = train_df)
y = train_df$y_numeric

cvfit_lasso = cv.glmnet(X, y, family = "binomial", alpha = 1)
plot(cvfit_lasso)
coef(cvfit_lasso, s = "lambda.min")

cvfit_enet = cv.glmnet(X, y, family = "binomial", alpha = 0.5)
plot(cvfit_enet)
coef(cvfit_enet, s = "lambda.min")
```

## Polynomial Transformations and Interaction Terms

1. Age: Scatterplots with LOESS smoothing show a nonlinear (U-shaped) relationship between age and the probability of subscription. This suggests that a quadratic transformation (age + age²) may improve model fit by capturing this curved relationship.

2. Consumer Confidence Index (cons.conf.idx): This variable also shows a nonlinear relationship with respect to subscription likelihood. The "w-shaped" plot suggests that a fourth degree polynomial transformation may be appropriate to account for this curvature.

3. euribor_binned * month: The Euribor 3-month rate captures economic conditions at the time of contact, and subscription likelihood varies substantially by month. Including an interaction between euribor_binned and month allows the model to account for possible seasonal effects of macroeconomic conditions.

4. education * job: These two categorical variables both represent aspects of a client’s socioeconomic profile. While we had hoped that this interaction would capture the relationship between education and job type, the wide variety of job titles in the dataset makes this interaction too complex to be useful. We will not include this interaction in the final model.

```{r}
train_df$age_sq = train_df$age^2

poly_cons_conf = poly(train_df$cons.conf.idx, degree = 4, raw = TRUE)
colnames(poly_cons_conf) = paste0("cci_poly", 1:4)
train_df = cbind(train_df, poly_cons_conf)

X_complex = model.matrix(y_numeric ~ . + age_sq + 
                         cci_poly1 + cci_poly2 + cci_poly3 + cci_poly4 + 
                         euribor_binned:month - 1, data = train_df)

y = train_df$y_numeric

cvfit_complex = cv.glmnet(X_complex, y, family = "binomial", alpha = 1)
plot(cvfit_complex)
coef(cvfit_complex, s = "lambda.min")
```

## Model Evaluation

```{r}
test_df$age_sq = test_df$age^2

poly_cons_conf_test = poly(test_df$cons.conf.idx, degree = 4, raw = TRUE)
colnames(poly_cons_conf_test) = paste0("cci_poly", 1:4)
test_df = cbind(test_df, poly_cons_conf_test)

X_test = model.matrix(y_numeric ~ . + age_sq + 
                      cci_poly1 + cci_poly2 + cci_poly3 + cci_poly4 + 
                      euribor_binned:month - 1, data = test_df)

probs = predict(cvfit_complex, newx = X_test, type = "response", s = "lambda.min")
true = test_df$y_numeric

threshold = 0.5
preds = ifelse(probs >= threshold, 1, 0)

conf = confusionMatrix(as.factor(preds), as.factor(true), positive = "1")

sensitivity = conf$byClass["Sensitivity"]
specificity = conf$byClass["Specificity"]
ppv = conf$byClass["Pos Pred Value"]
npv = conf$byClass["Neg Pred Value"]
prevalence = mean(true)

clr_roc_obj = roc(true, as.numeric(probs))
auroc = auc(clr_roc_obj)

clr_results = list(
  Sensitivity = sensitivity,
  Specificity = specificity,
  PPV = ppv,
  NPV = npv,
  Prevalence = prevalence,
  AUROC = auroc
)
print(clr_results)
```

## Model Performance Summary

| Metric          | Value     | Interpretation                                                               |
|-----------------|-----------|------------------------------------------------------------------------------|
| **Sensitivity** | 0.2373    | Model only caught ~24% of actual positive cases (true yes)                   |
| **Specificity** | 0.9856    | Model correctly ruled out ~99% of negative cases (true no)                   |
| **PPV**         | 0.6776    | 67.8% of predicted “yes” were actually correct                               |
| **NPV**         | 0.9101    | 91.0% of predicted “no” were actually correct                                |
| **Prevalence**  | 0.1132    | Only ~11% of observations are actual “yes” (class imbalance is common here)  |
| **AUROC**       | 0.7919    |                                                                              |

# 5: Predictive Model 2 (Linear Deterministic Analysis)

## Data Preparation

```{r}
link <- "https://raw.githubusercontent.com/tblakearmstrong/SMU-MSDS/refs/heads/main/Stats%206372/Project%202/bank-full.csv"
link2 <- "https://raw.githubusercontent.com/tblakearmstrong/SMU-MSDS/refs/heads/main/Stats%206372/Project%202/bank-additional-full.csv"
bank <- read.csv(link2, header =TRUE, sep=";")  #Pulling in the additional full currently
bank <- bank %>% 
  #dplyr::select(-response_num) %>% 
  dplyr::mutate(log_duration = log(duration+1))
bank$y = factor(bank$y, levels = c("no", "yes"))
```

## EDA for LDA/QDA Assumptions

```{r}
pairs(bank[, c("age", "duration")], col = as.numeric(factor(bank$y)))

ggplot(bank, aes(x=duration, fill=y)) + 
    geom_density(alpha=0.5) + theme_minimal()
```

```{r lda_model, echo=F, message=F, warning=F}
library(MASS)
library(caret)
library(pROC)
library(dplyr)
library(corrplot)
library(GGally)

set.seed(123)

lda_data <- bank %>%
  dplyr::select(-duration, -emp.var.rate, -pdays, -log_duration)

#Scale numeric predictors to handle high dimensionality and ensure comparability
lda_numeric_cols <- lda_data %>% dplyr::select(where(is.numeric))
lda_scaled_numeric <- as.data.frame(scale(lda_numeric_cols))
lda_bank_scaled <- bind_cols(lda_scaled_numeric, y = bank$y)

#Check Correlations since they have to be MVN and not correlated, there are not any MVN with good separation in this dataset, LDA is likely not appropriate to use here.
#ggpairs(lda_bank_scaled, aes(color=y))
corrplot(cor(lda_scaled_numeric), method = "color", tl.cex = 0.7)

#Model
fitControl<-trainControl(method="repeatedcv",number=5,repeats=1,classProbs=TRUE, summaryFunction=twoClassSummary)

#LDA less highly correlated factors and duration
lda.fit<-train(y~ age + campaign + euribor3m,
               data=lda_bank_scaled,
               method="lda",
               trControl=fitControl,
               metric="ROC")
summary(lda.fit)
lda.fit


#Computing predicted probabilities on the training data
lda.predictions <- predict(lda.fit, newdata = lda_bank_scaled, type = "prob")[,"yes"]

#AUROC Curve
lda_roc_obj <- roc(lda_bank_scaled$y, lda.predictions, levels = c("no", "yes"))
plot(lda_roc_obj)

#Best threshold (Youden’s J index)
coords(lda_roc_obj, "best", ret = "threshold")
threshold <- coords(lda_roc_obj, "best", ret = "threshold")[[1]]

#Confusion Matrix
lda_predicted_class <- factor(ifelse(lda.predictions > threshold, "yes", "no"), levels = c("yes", "no"))
confusionMatrix(lda_predicted_class, lda_bank_scaled$y, positive = "yes")
```


# 6: Predictive Model 3 (Quadratic Deterministic Analysis)

```{r qda_model, echo=F, message=F, warning=F}
library(MASS)
library(caret)
library(pROC)
library(dplyr)
library(corrplot)
library(GGally)

set.seed(123)

qda_data <- bank %>%
  dplyr::select(-duration, -emp.var.rate, -pdays, -log_duration)

#Scale numeric predictors to handle high dimensionality and ensure comparability
qda_numeric_cols <- qda_data %>% dplyr::select(where(is.numeric))
qda_scaled_numeric <- as.data.frame(scale(qda_numeric_cols))
qda_bank_scaled <- bind_cols(qda_scaled_numeric, y = bank$y)

#Model
fitControl<-trainControl(method="repeatedcv",number=5,repeats=1,classProbs=TRUE, summaryFunction=twoClassSummary)

#QDA, no variables really meet the criteria of multivariate normal, but the three included in lda are the closest, continue with same in QDA
qda.fit<-train(y ~ age + campaign + euribor3m,
               data=qda_bank_scaled,
               method="qda",
               trControl=fitControl,
               metric="ROC")
summary(qda.fit)
qda.fit

#Computing predicted probabilities on the training data
qda.predictions <- predict(qda.fit, newdata = qda_bank_scaled, type = "prob")[,"yes"]

#AUROC Curve
qda_roc_obj <- roc(qda_bank_scaled$y, qda.predictions, levels = c("no", "yes"))
plot(qda_roc_obj)

#Best threshold (Youden’s J index)
coords(qda_roc_obj, "best", ret = "threshold")
threshold <- coords(qda_roc_obj, "best", ret = "threshold")[[1]]

#Confusion Matrix
qda_predicted_class <- factor(ifelse(qda.predictions > threshold, "yes", "no"), levels = c("yes", "no"))
confusionMatrix(qda_predicted_class, qda_bank_scaled$y, positive = "yes")
```

# 7: Predictive Model 4 (Non-Parametric Model)

```{r non-parametric, echo = FALSE, warning = FALSE, message = FALSE} 
library(randomForest)
library(tidyverse)
library(caret)
library(dplyr)
library(pROC)

set.seed(123)

#Reset data table
rf_bank <- read.csv(link2, header =TRUE, sep=";")
rf_bank <- rf_bank %>% dplyr::select(-duration) %>%  mutate(across(where(is.character), as.factor))

#Train Control
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = twoClassSummary)

#Model
rf.fit <- train(y ~ ., data = rf_bank, 
                method = "rf", 
                trControl = fitControl, 
                metric = "ROC",
                ntree=100)
summary(rf.fit)
rf.fit
var_imp <- varImp(rf.fit)
plot(var_imp, top = 20, main = "Variable Importance")

#Predict probabilities (on validation set)
rf.predictions <- predict(rf.fit, rf_bank, type = "prob")[,"yes"]


#AUROC Curve
rf_roc_obj <- roc(rf_bank$y, rf.predictions, levels = c("no", "yes"))
plot(rf_roc_obj)

#Best threshold (Youden’s J index)
coords(rf_roc_obj, "best", ret = "threshold")
threshold <- coords(rf_roc_obj, "best", ret = "threshold")[[1]]

#Confusion Matrix
rf_predicted_class <- factor(ifelse(rf.predictions > threshold, "yes", "no"), levels = c("yes", "no"))
confusionMatrix(rf_predicted_class, rf_bank$y, positive = "yes")
```

# 8: Comparative Summary of Predictive Model Performance

## Model Performance Interpretation

In the context of predicting whether a customer will subscribe to a term deposit we consider several key metrics:

* Sensitivity (True Positive Rate): The proportion of actual subscribers correctly identified by the model. High sensitivity means a model would perform better at identifying potential subscribers.
* Specificity (True Negative Rate): The proportion of non-subscribers correctly identified. High specificity in a model would mean we would avoid targeting unlikely customers.
* PPV (Positive Predictive Value): Of all customers predicted to subscribe, what proportion actually did. High PPV would mean that our predictions are reliable when we say "yes."
* NPV (Negative Predictive Value): Of all customers predicted not to subscribe, the proportion who truly did not. High NPV would show that our model is reliable when saying "no."
Prevalence & AUROC: Prevalence reflects how common it is for customers to subscribe overall (typically low in this dataset), which can affect interpretation of PPV and NPV. AUROC (Area Under the ROC Curve) summarizes how well the model separates subscribers from non-subscribers across all thresholds—a higher AUROC means better overall discrimination.

### Model Performance Priorities

Since a phone marketing campaign has real costs, PPV is crucial: these marketing expenses are best used to target customers who are truly likely to subscribe. However, sensitivity is also important if we don't want to miss potential customers. Our recommendation would be to choose models that prioritize PPV and sensitivity, with specificity and NPV being less important.

## ROC Curves

```{r all_combined_roc, message = F, warning = F}
library(pROC)
#plot(roc_obj, col = "blue")
plot(clr_roc_obj, col = "blue", lwd = 2)
lines(lda_roc_obj, col = "green")
lines(qda_roc_obj, col = "red")
lines(rf_roc_obj, col = "purple")

legend("bottomright", 
       legend = c("Multiple Logistic - Complex", "LDA", "QDA", "Random Forest"),
       col = c("blue", "green", "red", "purple"),
       lwd = 2)
```

## Summary Table of Comparative Metrics

| Model                  | Sensitivity | Specificity | PPV     | NPV     | Prevalence | AUROC  |
|------------------------|-------------|-------------|---------|---------|------------|--------|
| Interpretive Model     | 0.4132      | 0.9704      | 0.6408  | 0.9283  | 0.1132     | 0.9310 |
| Complex Logistic (CLR) | 0.2373      | 0.9856      | 0.6776  | 0.9101  | 0.1132     | 0.7919 |
| LDA                    | 0.7116      | 0.7210      | 0.2446  | 0.9517  | 0.1127     | 0.7468 |
| QDA                    | 0.6970      | 0.7394      | 0.2534  | 0.9505  | 0.1127     | 0.7509 |
| Random Forest          | 0.9901      | 0.9882      | 0.9144  | 0.9987  | 0.1127     | 0.9993 |

### CLR Metrics

```{r}
clr_conf = confusionMatrix(as.factor(preds), as.factor(true), positive = "1")

sensitivity = clr_conf$byClass["Sensitivity"]
specificity = clr_conf$byClass["Specificity"]
ppv = clr_conf$byClass["Pos Pred Value"]
npv = clr_conf$byClass["Neg Pred Value"]
prevalence = mean(true)

clr_roc_obj = roc(true, as.numeric(probs))
auroc = auc(clr_roc_obj)

clr_results = list(
  Sensitivity = sensitivity,
  Specificity = specificity,
  PPV = ppv,
  NPV = npv,
  Prevalence = prevalence,
  AUROC = auroc
)
print(clr_results)
```


### LDA Metrics

```{r}
lda_conf = confusionMatrix(lda_predicted_class, lda_bank_scaled$y, positive = "yes")

lda_sensitivity = lda_conf$byClass["Sensitivity"]
lda_specificity = lda_conf$byClass["Specificity"]
lda_ppv = lda_conf$byClass["Pos Pred Value"]
lda_npv = lda_conf$byClass["Neg Pred Value"]
lda_prevalence = mean(lda_bank_scaled$y == "yes")
lda_auroc = auc(lda_roc_obj)

lda_results = list(
  Sensitivity = lda_sensitivity,
  Specificity = lda_specificity,
  PPV = lda_ppv,
  NPV = lda_npv,
  Prevalence = lda_prevalence,
  AUROC = lda_auroc
)

print(lda_results)
```

### QDA Metrics

```{r}
qda_conf = confusionMatrix(qda_predicted_class, qda_bank_scaled$y, positive = "yes")

qda_sensitivity = qda_conf$byClass["Sensitivity"]
qda_specificity = qda_conf$byClass["Specificity"]
qda_ppv = qda_conf$byClass["Pos Pred Value"]
qda_npv = qda_conf$byClass["Neg Pred Value"]
qda_prevalence = mean(qda_bank_scaled$y == "yes")
qda_auroc = auc(qda_roc_obj)

qda_results = list(
  Sensitivity = qda_sensitivity,
  Specificity = qda_specificity,
  PPV = qda_ppv,
  NPV = qda_npv,
  Prevalence = qda_prevalence,
  AUROC = qda_auroc
)

print(qda_results)

```

### Random Forest Metrics

```{r}
rf_conf = confusionMatrix(rf_predicted_class, rf_bank$y, positive = "yes")

rf_sensitivity = rf_conf$byClass["Sensitivity"]
rf_specificity = rf_conf$byClass["Specificity"]
rf_ppv = rf_conf$byClass["Pos Pred Value"]
rf_npv = rf_conf$byClass["Neg Pred Value"]
rf_prevalence = mean(rf_bank$y == "yes")
rf_auroc = auc(rf_roc_obj)

rf_results = list(
  Sensitivity = rf_sensitivity,
  Specificity = rf_specificity,
  PPV = rf_ppv,
  NPV = rf_npv,
  Prevalence = rf_prevalence,
  AUROC = rf_auroc
)

print(rf_results)
```

# Appendix: Data Sources

Data Source Citation: 

  [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. 
  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.
